---
title: "Wh-Question Polarity Model: Simulations & Model Comparison"
format:
  html:
    code-fold: true
    toc: true
  pdf:
    toc: true
execute:
  warning: false
---

## Setup

```{python}
from __future__ import annotations

import json
from pathlib import Path

import matplotlib
import matplotlib.pyplot as plt
import numpy as np

# Import model from single source of truth
from model import Model

# Configuration
SCRIPT_DIR = Path(".").resolve()
N_VIALS = 10

matplotlib.rcParams.update({'pdf.fonttype': 42, 'font.family': 'sans-serif', 'font.size': 11})
COLORS = {'find_uncont': '#4DAF4A', 'find_cont': '#A50F15'}  # Green/red to match empirical figures

# Create model with fitted hyperparameters
model = Model(alpha_r=3.0, alpha_q=3.0, alpha_policy=3.0, gamma=0.75, length_cost=0.01)
```

### Experiment 1: Goal × Base Rate

```{python}
#| label: fig-exp1-predictions
#| fig-cap: "Model predictions for Experiment 1: Goal alignment across base rates"

# Match the empirical base rates from Experiment 1
base_rates = np.array([0.2, 0.5, 0.8])
pred_uncont = []
pred_cont = []

print("Computing Exp 1 predictions...")
for br in base_rates:
    p_uncont = 1 - br
    preds = model.predict_all('singleton', p_uncont=p_uncont, n_vials=N_VIALS)
    pred_uncont.append(preds['find_uncont'])
    pred_cont.append(preds['find_cont'])
    print(f"  BR={br}: find_uncont={preds['find_uncont']:.2f}, find_cont={preds['find_cont']:.2f}")

fig, ax = plt.subplots(figsize=(5, 4))

# Line plot matching empirical figure style
ax.plot(base_rates, pred_uncont, 'o-', color=COLORS['find_uncont'], linewidth=2, markersize=8, label='Find uncontaminated')
ax.plot(base_rates, pred_cont, 'o-', color=COLORS['find_cont'], linewidth=2, markersize=8, label='Find contaminated')

ax.set_xlabel('Base rate of contamination')
ax.set_ylabel('P("Which are uncontaminated?")')
ax.set_xticks(base_rates)
ax.set_xticklabels(['20%', '50%', '80%'])
ax.set_ylim(0, 1)
ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])
ax.legend(title='Goal', loc='upper left', frameon=False)
ax.spines[['top', 'right']].set_visible(False)

plt.tight_layout()
plt.savefig(SCRIPT_DIR / 'exp1_model_predictions.pdf', format='pdf', bbox_inches='tight')
plt.show()
```

### Experiment 2: Goal × Decision Structure

```{python}
#| label: fig-exp2-predictions
#| fig-cap: "Model predictions for Experiment 2: Goal alignment depends on decision structure"

# Compute predictions at 50% base rate for both decision types
predictions = {}

for dt in ['singleton', 'set_id']:
    preds = model.predict_all(dt, p_uncont=0.5, n_vials=N_VIALS)
    for g_name in ['find_uncont', 'find_cont']:
        predictions[(dt, g_name)] = preds[g_name]
        print(f"{dt}, {g_name}: {preds[g_name]:.2%}")

# Bar plot matching empirical figure style (grouped by decision structure)
fig, ax = plt.subplots(figsize=(5, 4))

x = np.array([0, 1])  # Singleton, Set ID
width = 0.35

# Group bars by decision structure, color by goal
find_uncont_vals = [predictions[('singleton', 'find_uncont')], predictions[('set_id', 'find_uncont')]]
find_cont_vals = [predictions[('singleton', 'find_cont')], predictions[('set_id', 'find_cont')]]

ax.bar(x - width/2, find_uncont_vals, width, label='Find uncontaminated', color=COLORS['find_uncont'])
ax.bar(x + width/2, find_cont_vals, width, label='Find contaminated', color=COLORS['find_cont'])

ax.set_xlabel('Decision structure')
ax.set_ylabel('P("Which are not contaminated?")')
ax.set_xticks(x)
ax.set_xticklabels(['Singleton', 'Set ID'])
ax.set_ylim(0, 1)
ax.set_yticks([0, 0.25, 0.5, 0.75, 1.0])
ax.legend(title='Goal', loc='upper right', frameon=False)
ax.spines[['top', 'right']].set_visible(False)

plt.tight_layout()
plt.savefig(SCRIPT_DIR / 'exp2_model_predictions.pdf', format='pdf', bbox_inches='tight')
plt.show()

# Print effect sizes
singleton_effect = predictions[('singleton', 'find_uncont')] - predictions[('singleton', 'find_cont')]
setid_effect = predictions[('set_id', 'find_uncont')] - predictions[('set_id', 'find_cont')]
print(f"\nSingleton effect: {singleton_effect:.0%}")
print(f"Set-ID effect: {setid_effect:.0%}")
print(f"Interaction: {singleton_effect - setid_effect:.0%}")
```

### Combined Figure

```{python}
#| label: fig-combined-predictions
#| fig-cap: "Combined model predictions for both experiments"

# Recompute Exp 1 predictions
base_rates = np.array([0.2, 0.5, 0.8])
exp1_pred_uncont = []
exp1_pred_cont = []

for br in base_rates:
    preds = model.predict_all('singleton', p_uncont=1-br, n_vials=N_VIALS)
    exp1_pred_uncont.append(preds['find_uncont'])
    exp1_pred_cont.append(preds['find_cont'])

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3.5))

# Panel A: Experiment 1
ax1.plot(base_rates, exp1_pred_uncont, 'o-', color=COLORS['find_uncont'], linewidth=2, markersize=8, label='Find uncontaminated')
ax1.plot(base_rates, exp1_pred_cont, 'o-', color=COLORS['find_cont'], linewidth=2, markersize=8, label='Find contaminated')
ax1.set_xlabel('Base rate of contamination')
ax1.set_ylabel('P("Which are uncontaminated?")')
ax1.set_xticks(base_rates)
ax1.set_xticklabels(['20%', '50%', '80%'])
ax1.set_ylim(0, 1)
ax1.set_yticks([0, 0.25, 0.5, 0.75, 1.0])
ax1.legend(title='Goal', loc='upper left', frameon=False, fontsize=9)
ax1.spines[['top', 'right']].set_visible(False)
ax1.set_title('A. Experiment 1: Goal × Base Rate', fontsize=11, fontweight='bold', loc='left')

# Panel B: Experiment 2
x = np.array([0, 1])
width = 0.35
find_uncont_vals = [predictions[('singleton', 'find_uncont')], predictions[('set_id', 'find_uncont')]]
find_cont_vals = [predictions[('singleton', 'find_cont')], predictions[('set_id', 'find_cont')]]

ax2.bar(x - width/2, find_uncont_vals, width, label='Find uncontaminated', color=COLORS['find_uncont'])
ax2.bar(x + width/2, find_cont_vals, width, label='Find contaminated', color=COLORS['find_cont'])
ax2.set_xlabel('Decision structure')
ax2.set_ylabel('P("Which are uncontaminated?")')
ax2.set_xticks(x)
ax2.set_xticklabels(['Singleton', 'Set ID'])
ax2.set_ylim(0, 1)
ax2.set_yticks([0, 0.25, 0.5, 0.75, 1.0])
ax2.legend(title='Goal', loc='upper right', frameon=False, fontsize=9)
ax2.spines[['top', 'right']].set_visible(False)
ax2.set_title('B. Experiment 2: Goal × Decision', fontsize=11, fontweight='bold', loc='left')

plt.tight_layout()
plt.savefig(SCRIPT_DIR / 'model_predictions.pdf', format='pdf', bbox_inches='tight')
plt.show()
```

## Model Comparison: Experiment 1

```{python}
# Experiment 1 data
EXP1_DATA = {
    ('uncont', 0.2): (10, 23),
    ('uncont', 0.5): (17, 36),
    ('uncont', 0.8): (21, 31),
    ('cont', 0.2): (4, 28),
    ('cont', 0.5): (2, 21),
    ('cont', 0.8): (7, 24),
}

def compute_waic_brier(predictions, data):
    """Compute WAIC and Brier score over individual observations."""
    total_ll = 0.0
    total_brier = 0.0
    total_n = 0

    for key, (successes, total) in data.items():
        pred_p = np.clip(predictions[key], 1e-10, 1 - 1e-10)
        total_ll += successes * np.log(pred_p) + (total - successes) * np.log(1 - pred_p)
        total_brier += successes * (1 - pred_p)**2 + (total - successes) * pred_p**2
        total_n += total

    waic = -2 * total_ll
    brier = total_brier / total_n
    return waic, brier


# Null model
null_pred = {key: 0.5 for key in EXP1_DATA}
null_waic, null_brier = compute_waic_brier(null_pred, EXP1_DATA)

# Goal-matching model (MLE)
uncont_s = sum(EXP1_DATA[k][0] for k in EXP1_DATA if k[0] == 'uncont')
uncont_t = sum(EXP1_DATA[k][1] for k in EXP1_DATA if k[0] == 'uncont')
cont_s = sum(EXP1_DATA[k][0] for k in EXP1_DATA if k[0] == 'cont')
cont_t = sum(EXP1_DATA[k][1] for k in EXP1_DATA if k[0] == 'cont')

gm_pred = {k: (uncont_s/uncont_t if k[0] == 'uncont' else cont_s/cont_t) for k in EXP1_DATA}
gm_waic, gm_brier = compute_waic_brier(gm_pred, EXP1_DATA)

# Full RSA model
rsa_pred = {}
for (goal, br) in EXP1_DATA:
    g_name = 'find_uncont' if goal == 'uncont' else 'find_cont'
    rsa_pred[(goal, br)] = model.predict(g_name, 'singleton', p_uncont=1-br, n_vials=N_VIALS)
rsa_waic, rsa_brier = compute_waic_brier(rsa_pred, EXP1_DATA)

import pandas as pd
from IPython.display import Markdown

# Build model comparison dataframe
exp1_models = pd.DataFrame({
    'Model': ['Null', 'Goal-matching', 'Full RSA'],
    'k': [0, 2, 5],
    'WAIC': [null_waic, gm_waic, rsa_waic],
    'Brier': [null_brier, gm_brier, rsa_brier]
})

# Find best (lowest) WAIC
best_waic_idx = exp1_models['WAIC'].idxmin()

# Format with bold for best
def format_exp1_row(row, idx):
    if idx == best_waic_idx:
        return f"| **{row['Model']}** | {row['k']} | **{row['WAIC']:.1f}** | **{row['Brier']:.3f}** |"
    return f"| {row['Model']} | {row['k']} | {row['WAIC']:.1f} | {row['Brier']:.3f} |"

table_md = "| Model | k | WAIC | Brier |\n|:------|--:|-----:|------:|\n"
for idx, row in exp1_models.iterrows():
    table_md += format_exp1_row(row, idx) + "\n"

display(Markdown(f"**Experiment 1 Model Comparison**\n\n{table_md}"))
```

## Model Comparison: Experiment 2

```{python}
# Experiment 2 data
EXP2_DATA = {
    'singleton': {
        'find_uncont': (29, 38),
        'find_cont': (9, 42)
    },
    'set_id': {
        'find_uncont': (24, 36),
        'find_cont': (18, 44)
    }
}

def exp2_waic_brier(predictions):
    """Compute WAIC and Brier for Exp 2 format."""
    total_ll = 0.0
    total_brier = 0.0
    total_n = 0

    for dt in ['singleton', 'set_id']:
        for goal in ['find_uncont', 'find_cont']:
            s, t = EXP2_DATA[dt][goal]
            pred_p = np.clip(predictions[dt][goal], 1e-10, 1 - 1e-10)
            total_ll += s * np.log(pred_p) + (t - s) * np.log(1 - pred_p)
            total_brier += s * (1 - pred_p)**2 + (t - s) * pred_p**2
            total_n += t

    return -2 * total_ll, total_brier / total_n


# Null model
null2_pred = {'singleton': {'find_uncont': 0.5, 'find_cont': 0.5},
              'set_id': {'find_uncont': 0.5, 'find_cont': 0.5}}
null2_waic, null2_brier = exp2_waic_brier(null2_pred)

# Goal-matching model (same effect for both decision types)
all_uncont_s = EXP2_DATA['singleton']['find_uncont'][0] + EXP2_DATA['set_id']['find_uncont'][0]
all_uncont_t = EXP2_DATA['singleton']['find_uncont'][1] + EXP2_DATA['set_id']['find_uncont'][1]
all_cont_s = EXP2_DATA['singleton']['find_cont'][0] + EXP2_DATA['set_id']['find_cont'][0]
all_cont_t = EXP2_DATA['singleton']['find_cont'][1] + EXP2_DATA['set_id']['find_cont'][1]

p_uncont_goal = all_uncont_s / all_uncont_t
p_cont_goal = all_cont_s / all_cont_t

gm2_pred = {
    'singleton': {'find_uncont': p_uncont_goal, 'find_cont': p_cont_goal},
    'set_id': {'find_uncont': p_uncont_goal, 'find_cont': p_cont_goal}
}
gm2_waic, gm2_brier = exp2_waic_brier(gm2_pred)

# Exhaustive-only RSA (use set_id utility for both - assumes exhaustive answers)
exh_preds = model.predict_all('set_id', p_uncont=0.5, n_vials=N_VIALS)
exh_pred = {dt: exh_preds for dt in ['singleton', 'set_id']}
exh_waic, exh_brier = exp2_waic_brier(exh_pred)

# Mention-some only RSA (use singleton utility for both - assumes partial answers)
ms_preds = model.predict_all('singleton', p_uncont=0.5, n_vials=N_VIALS)
ms_pred = {dt: ms_preds for dt in ['singleton', 'set_id']}
ms_waic, ms_brier = exp2_waic_brier(ms_pred)

# Full RSA model (different utility for each decision type)
rsa2_pred = {
    'singleton': model.predict_all('singleton', p_uncont=0.5, n_vials=N_VIALS),
    'set_id': model.predict_all('set_id', p_uncont=0.5, n_vials=N_VIALS)
}
rsa2_waic, rsa2_brier = exp2_waic_brier(rsa2_pred)

# Build model comparison dataframe for Exp 2
exp2_models = pd.DataFrame({
    'Model': ['Null', 'Goal-matching', 'Exhaustive-only RSA', 'Mention-some only RSA', 'Full RSA'],
    'k': [0, 2, 5, 5, 5],
    'WAIC': [null2_waic, gm2_waic, exh_waic, ms_waic, rsa2_waic],
    'Brier': [null2_brier, gm2_brier, exh_brier, ms_brier, rsa2_brier]
})

# Find best (lowest) WAIC
best_waic_idx2 = exp2_models['WAIC'].idxmin()

# Format with bold for best
def format_exp2_row(row, idx):
    if idx == best_waic_idx2:
        return f"| **{row['Model']}** | {row['k']} | **{row['WAIC']:.1f}** | **{row['Brier']:.3f}** |"
    return f"| {row['Model']} | {row['k']} | {row['WAIC']:.1f} | {row['Brier']:.3f} |"

table_md2 = "| Model | k | WAIC | Brier |\n|:------|--:|-----:|------:|\n"
for idx, row in exp2_models.iterrows():
    table_md2 += format_exp2_row(row, idx) + "\n"

display(Markdown(f"**Experiment 2 Model Comparison**\n\n{table_md2}"))

# Compute interaction for later use
data_int = (EXP2_DATA['singleton']['find_uncont'][0]/EXP2_DATA['singleton']['find_uncont'][1] -
            EXP2_DATA['singleton']['find_cont'][0]/EXP2_DATA['singleton']['find_cont'][1]) - \
           (EXP2_DATA['set_id']['find_uncont'][0]/EXP2_DATA['set_id']['find_uncont'][1] -
            EXP2_DATA['set_id']['find_cont'][0]/EXP2_DATA['set_id']['find_cont'][1])
rsa_int = (rsa2_pred['singleton']['find_uncont'] - rsa2_pred['singleton']['find_cont']) - \
          (rsa2_pred['set_id']['find_uncont'] - rsa2_pred['set_id']['find_cont'])
```

## Summary

```{python}
# Create summary table
summary_data = pd.DataFrame({
    'Experiment': ['Exp 1', 'Exp 1', 'Exp 2', 'Exp 2'],
    'Comparison': ['Null vs Goal-matching', 'Goal-matching vs RSA',
                   'Null vs Goal-matching', 'Goal-matching vs RSA'],
    'ΔWAIC': [null_waic - gm_waic, gm_waic - rsa_waic,
              null2_waic - gm2_waic, gm2_waic - rsa2_waic]
})

summary_md = "| Experiment | Comparison | ΔWAIC |\n|:-----------|:-----------|------:|\n"
for _, row in summary_data.iterrows():
    delta = row['ΔWAIC']
    # Positive ΔWAIC means first model is worse (higher WAIC)
    summary_md += f"| {row['Experiment']} | {row['Comparison']} | {delta:+.1f} |\n"

display(Markdown(f"**Model Comparison Summary** (positive ΔWAIC favors second model)\n\n{summary_md}"))
```

```{python}
# Save all results
results = {
    'exp1_params': EXP1_PARAMS,
    'exp2_params': EXP2_PARAMS,
    'exp1': {
        'data': {f"{g}_{b}": {'s': s, 't': t} for (g, b), (s, t) in EXP1_DATA.items()},
        'models': {
            'null': {'waic': null_waic, 'brier': null_brier},
            'goal_matching': {'waic': gm_waic, 'brier': gm_brier},
            'full_rsa': {'waic': rsa_waic, 'brier': rsa_brier}
        }
    },
    'exp2': {
        'data': EXP2_DATA,
        'models': {
            'null': {'waic': null2_waic, 'brier': null2_brier},
            'goal_matching': {'waic': gm2_waic, 'brier': gm2_brier},
            'exhaustive_rsa': {'waic': exh_waic, 'brier': exh_brier},
            'mention_some_rsa': {'waic': ms_waic, 'brier': ms_brier},
            'full_rsa': {'waic': rsa2_waic, 'brier': rsa2_brier}
        }
    }
}

with open(SCRIPT_DIR / 'model_comparison_results.json', 'w') as f:
    json.dump(results, f, indent=2)
print(f"\nResults saved to {SCRIPT_DIR / 'model_comparison_results.json'}")
```
